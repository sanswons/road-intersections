{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# adjust display options\n",
    "pd.options.display.max_rows = 2000\n",
    "pd.options.display.max_columns = 2000\n",
    "pd.options.display.max_colwidth = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "city = 'Tucson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read pickle\n",
    "intersections_df_features = data_dir + city + '_intersections_df_features.pkl' \n",
    "intersections_df = pd.read_pickle(intersections_df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# take only those intersections which have 3 or more ways\n",
    "intersections_df = intersections_df[intersections_df['no_of_ways']>2]\n",
    "len(intersections_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add feature - number of unique ways at a node\n",
    "intersections_df['no_of_unique_ways'] = intersections_df['name'].apply(lambda x : len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ways_features_names = list(set([u'hgv', u'lanes', u'oneway', u'bicycle',\n",
    "       u'highway', u'bridge', u'layer', u'cycleway', u'sidewalk','maxspeed',\n",
    "       u'busway', u'abutters', u'bicycle_road', u'driving_side', u'ford',\n",
    "       u'ice_road', u'incline', u'junction', u'lit', u'motorroad','name',\n",
    "       u'mountain_pass', u'mtb:scale', u'mtb:scale:uphill', u'mtb:description',\n",
    "       u'overtaking', u'parking:condition', u'parking:lane', u'parking_places',\n",
    "       u'sac_scale', u'service', u'surface', u'tactile_paving', u'tracktype',\n",
    "       u'traffic_calming', u'trail_visibility', u'winter_road', u'place',\n",
    "       u'railway', u'electrified', u'embankment', u'route', u'tourism',\n",
    "       u'charge', u'location', u'narrow', u'tunnel', u'width', u'access',\n",
    "       u'agriculture', u'maxheight', u'maxlength', u'maxstay', u'maxwidth',\n",
    "       u'maxweight', u'minspeed', u'noexit']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features (expanded with values for each category in a feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intersections_expanded_df = copy.deepcopy(intersections_df)\n",
    "\n",
    "# function to count how many ways posses the feature in the given intersection \n",
    "def convert_to_bag_of_categories(x, categories):\n",
    "    v = [0]*len(categories)\n",
    "    x = collections.Counter(x)\n",
    "    for i in range(len(categories)):\n",
    "        if categories[i] in  x:\n",
    "            v[i]=x[categories[i]]\n",
    "    return v\n",
    "    \n",
    "    \n",
    "categories_all = []\n",
    "\n",
    "# features not to be expanded\n",
    "skip_features = ['name','no_of_ways']\n",
    "\n",
    "for feature in ways_features_names:\n",
    "    if feature in skip_features:\n",
    "        continue\n",
    "    categories = []\n",
    "    intersections_expanded_df[feature].apply(lambda x : categories.extend(x))\n",
    "    categories = list(set(categories))\n",
    "    intersections_expanded_df[feature] = intersections_expanded_df[feature].apply(convert_to_bag_of_categories, args = (categories,))\n",
    "    \n",
    "intersections_expanded_df['highway'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustering_feature_names = list(set([u'hgv', u'lanes', u'oneway', u'bicycle','maxspeed', \n",
    "    u'no_of_unique_ways', u'traffic_sign',u'highway', u'bridge', u'layer', u'cycleway', u'sidewalk',\n",
    "    u'busway', u'abutters', u'bicycle_road', u'driving_side', u'incline', u'junction', u'lit', u'motorroad',\n",
    "    u'overtaking',u'service', u'surface', u'tactile_paving', u'tracktype',u'maxheight', u'maxlength', \n",
    "    u'maxstay', u'maxwidth', u'maxweight', u'minspeed', u'noexit',u'place',u'crossing', u'toll',\n",
    "    u'traffic_calming', u'trail_visibility', u'winter_road', u'place',u'railway', u'electrified', \n",
    "    u'embankment', u'route', u'tourism',\n",
    "    u'charge', u'location', u'narrow', u'tunnel', u'width', u'access', u'ford',u'ice_road',\n",
    "    u'agriculture', u'parking:condition', u'parking:lane', u'parking_places',u'sac_scale', \n",
    "    u'mountain_pass', u'mtb:scale', u'mtb:scale:uphill', u'mtb:description',u'no_of_ways']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe for clustering\n",
    "1. create one feature vector by combining all features in clustering_feature_names\n",
    "2. split this feature vector to form column for each property in clustering_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clustering_df = pd.DataFrame()\n",
    "clustering_df['feature_vector']= intersections_expanded_df[clustering_feature_names].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flatten(nested):\n",
    "    flattened_list = []\n",
    "    for item in nested:\n",
    "        if str(type(item)) == \"<type 'list'>\":\n",
    "            flattened_list.extend(item)\n",
    "        else:\n",
    "            flattened_list.append(item)\n",
    "    return flattened_list\n",
    "\n",
    "clustering_df['feature_vector'] = clustering_df['feature_vector'].apply(flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_vectors = lambda x: pd.Series([i for i in '#*#'.join(map(str, x)).split('#*#')])\n",
    "clustering_df_sep =  clustering_df['feature_vector'][:].apply(split_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to categorical values\n",
    "colnames = clustering_df_sep.columns\n",
    "for col in colnames:\n",
    "    clustering_df_sep[col] = clustering_df_sep[col].astype('category')\n",
    "    clustering_df_sep[col] = clustering_df_sep[col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create feature matrix\n",
    "intersections_feature_matrix = clustering_df_sep.as_matrix()\n",
    "intersections_feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.use('Agg')\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans_name = 'kmeans' + city + '_clustered_intersection_df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# number of clusters\n",
    "from sklearn.cluster import KMeans\n",
    "k = 20\n",
    "kmeans_labels = KMeans(n_clusters=k, max_iter=500).fit_predict(intersections_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intersections_expanded_df['cluster_no'] = kmeans_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersections_expanded_df.to_pickle(data_dir+kmeans_name+'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spectral_name = 'spectral' + city + '_clustered_intersection_df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "spectral_labels = SpectralClustering(n_clusters=30, affinity= 'nearest_neighbors',\n",
    "                           assign_labels='kmeans').fit_predict(intersections_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersections_expanded_df['cluster_no'] = spectral_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersections_expanded_df.to_pickle(data_dir+spectral_name+'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBScan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbscan_name = 'dbscan' + city + '_clustered_intersection_df_10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "dbscan_labels = DBSCAN(eps=0.02, min_samples=30, metric='euclidean', metric_params=None, algorithm ='auto', \n",
    "                       leaf_size=30, p=None, n_jobs=1).fit_predict(intersections_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersections_expanded_df['cluster_no'] = dbscan_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersections_expanded_df.to_pickle('../data/'+ dbscan_name+'.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
